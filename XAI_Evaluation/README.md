# XAI Evaluation Dataset

## Dataset Type
Author-Created Evaluation Dataset

## Purpose
Designed to evaluate explanation quality of:
- SHAP
- LIME
- Attention Visualization

## Dataset Size
200 manually labeled samples

## Data Composition
Includes:
- Explicit cyberbullying examples
- Implicit cyberbullying cases
- Multimodal aggressive content
- Ambiguous borderline cases

## Annotation Method
- Human-reviewed labeling
- Focus on explanation clarity assessment
- Used to measure:
  - Faithfulness
  - Robustness
  - Understandability

## Usage in Study
Used exclusively for evaluating interpretability performance of the MultiBully-XAI framework.

## Public Availability
This dataset was created specifically for explanation testing and is not externally sourced.

## Ethical Compliance
All examples were either synthetic or anonymized.
No personally identifiable information is included.
